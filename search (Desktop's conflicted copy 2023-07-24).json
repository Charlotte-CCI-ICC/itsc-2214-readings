[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ITSC 2214 - Data Structures and Algorithms - Summer 2023",
    "section": "",
    "text": "Preface\nThis website contains a set of readings for ITSC 2214 - Data Structures and Algorithms."
  },
  {
    "objectID": "20_trees.html#background",
    "href": "20_trees.html#background",
    "title": "20  Tree Data Structure",
    "section": "20.1 Background",
    "text": "20.1 Background\nWhen we first begin to learn about data structures, we often encounter linear structures such as arrays, linked lists, stacks, and queues. These structures, as the term ‘linear’ suggests, store data in a sequential manner (Figure 20.1). This makes them great for situations where the data can be naturally expressed as a sequence, for instance, a to-do list or a queue at a coffee shop.\n\n\n\n\n\n\n\n\nG\n\n  \n\n1\n\n 1   \n\n2\n\n 2   \n\n1-&gt;2\n\n    \n\n3\n\n 3   \n\n2-&gt;3\n\n    \n\n4\n\n 4   \n\n3-&gt;4\n\n    \n\n5\n\n 5   \n\n4-&gt;5\n\n   \n\n\nFigure 20.1: A representation of a linked list structure, highlighting its linear nature.\n\n\n\n\nLet’s consider the linked list. Each node in the linked list has a reference to the next node, creating a chain of elements. This works well when the data in the structure has a natural sequential or linear relationship. However, as we delve deeper into more complex data problems, we begin to see that not all data fits neatly into a linear relationship.\nConsider an organizational hierarchy within a company. Each person (except the CEO) reports to exactly one person. However, each manager can have multiple direct reports. In this case, each node (person) might need to reference more than one node (Figure 20.2). Using a linked list to represent this data would be cumbersome, as it would not capture the multiple relationships that exist between a manager and their direct reports.\n\n\n\n\n\n\n\n\nG\n\n  \n\nCEO\n\n CEO   \n\nManager1\n\n Manager1   \n\nCEO-&gt;Manager1\n\n    \n\nManager2\n\n Manager2   \n\nCEO-&gt;Manager2\n\n    \n\nEmployee1\n\n Employee1   \n\nManager1-&gt;Employee1\n\n    \n\nEmployee2\n\n Employee2   \n\nManager1-&gt;Employee2\n\n    \n\nEmployee3\n\n Employee3   \n\nManager2-&gt;Employee3\n\n    \n\nEmployee4\n\n Employee4   \n\nManager2-&gt;Employee4\n\n   \n\n\nFigure 20.2: An example of an organizational hierarchy within a company, illustrating the non-linear relationships that exist.\n\n\n\n\nAnother example is a file system on your computer. Each folder can contain multiple files or other folders. But, each file or folder is contained within exactly one other folder. Once again, we see the need for a data structure that can capture these multiple relationships (Figure 20.3).\n\n\n\n\n\n\n\n\nG\n\n  \n\nRoot\n\n Root   \n\nFolder1\n\n Folder1   \n\nRoot-&gt;Folder1\n\n    \n\nFile1\n\n File1   \n\nRoot-&gt;File1\n\n    \n\nSubfolder1\n\n Subfolder1   \n\nFolder1-&gt;Subfolder1\n\n    \n\nFile2\n\n File2   \n\nFolder1-&gt;File2\n\n    \n\nFile3\n\n File3   \n\nSubfolder1-&gt;File3\n\n    \n\nFile4\n\n File4   \n\nSubfolder1-&gt;File4\n\n   \n\n\nFigure 20.3: A representation of a simple file system, showing how folders can contain multiple other folders or files.\n\n\n\n\nThese examples bring to light a common pattern: there are situations where our data is not linear, but hierarchical. Hierarchies exist in various forms in the real world, from biological classifications to the layout of web pages, and modeling these hierarchies accurately in our programs allows us to reflect the reality more truthfully.\nEnter the concept of Trees.\nA tree in computer science is a hierarchical data structure that can model these kinds of relationships (Figure 20.4). This structure gets its name from a real-world tree, but with a twist - the tree data structure is often visualized with the root at the top and the leaves at the bottom, resembling an upside-down real-world tree.\n\n\n\n\n\n\n\n\nG\n\n  \n\nRoot\n\n Root   \n\nChild1\n\n Child1   \n\nRoot-&gt;Child1\n\n    \n\nChild2\n\n Child2   \n\nRoot-&gt;Child2\n\n    \n\nChild3\n\n Child3   \n\nRoot-&gt;Child3\n\n    \n\nGrandchild1\n\n Grandchild1   \n\nChild1-&gt;Grandchild1\n\n    \n\nGrandchild2\n\n Grandchild2   \n\nChild1-&gt;Grandchild2\n\n    \n\nGrandchild3\n\n Grandchild3   \n\nChild3-&gt;Grandchild3\n\n   \n\n\nFigure 20.4: An illustration of a simple tree data structure, with key components labeled.\n\n\n\n\nThe tree structure is a fundamental shift from our previously understood data structures. It can open new doors to solving problems and provide an efficient way to organize and model complex relationships in our data.\nIn the following sections, we’ll take a deeper dive into the world of trees, understanding their properties, variations, and how they can revolutionize the way we think about hierarchical data relationships."
  },
  {
    "objectID": "20_trees.html#introduction-to-trees",
    "href": "20_trees.html#introduction-to-trees",
    "title": "20  Tree Data Structure",
    "section": "20.2 Introduction to Trees",
    "text": "20.2 Introduction to Trees\nAfter establishing the need for a data structure that can handle more complex relationships, we can now formally introduce the concept of trees.\nA tree in computer science is an abstract data type that simulates a hierarchical structure with a set of interconnected nodes. The key characteristic that separates trees from other data structures is that no node in the tree may be connected to more than one parent node, thereby preventing any possibility of a loop in the data structure.\nLet’s get familiar with some fundamental tree terminologies (see Figure 20.5):\n\nNode: A unit or location in the tree where data is stored. It’s similar to a link in a linked list or an element in an array.\nRoot: The topmost node in the tree that doesn’t have a parent.\nEdge: The connection between two nodes.\nParent: A node which has one or more child nodes.\nChild: A node which has a parent node.\nLeaf: A node which does not have any child nodes.\nSubtree: A tree consisting of a node and its descendants.\nDegree: The number of children of a node.\nLevel: The distance from the root, measured in edges.\nHeight: The distance from the node to its furthest leaf.\nDepth: The distance from the node to the root.\n\n\n\n\n\n\n\n\n\nG\n\n  \n\nA\n\n Root (A) Node   \n\nB\n\n Child (B) Node Level: 1 Depth: 1 Parent of: F, G   \n\nA-&gt;B\n\n    \n\nC\n\n Child (C) Node Degree: 2  Parent of: D, E   \n\nA-&gt;C\n\n    \n\nF\n\n Leaf (F) Node Depth: 2   \n\nB-&gt;F\n\n    \n\nG\n\n Leaf (G) Node Depth: 2   \n\nB-&gt;G\n\n    \n\nD\n\n Leaf (D) Node Depth: 2   \n\nC-&gt;D\n\n    \n\nE\n\n Leaf (E) Node Depth: 2   \n\nC-&gt;E\n\n   \n\n\nFigure 20.5: A simple tree illustrating various tree terminologies. Node A is the root, nodes B and C are children of A. Node C, having two children, demonstrates the degree of a node. Nodes D, E, F, G are leaf nodes. The subtree consists of Node C and its descendants (D, E). The level is demonstrated by the level of Node B (Level 1). The depth of Node D is 2 (from Root A). The height of the tree is 2 (distance from the Root A to furthest leaf).\n\n\n\n\nThe concept of trees becomes truly interesting when we delve into the various types of trees. Different types of trees can be used to solve different types of problems, and it’s crucial to choose the right type for a given problem.\nThe simplest form of a tree is a General Tree, where each node can have any number of child nodes. An example of where a general tree might be useful is in the representation of a file system on a computer. In this system, each folder can contain any number of files or folders. We can illustrate this with a diagram (Figure 20.6).\n\n\n\n\n\n\n\n\nG\n\n  \n\nRoot\n\n Root   \n\nFolder1\n\n Folder1   \n\nRoot-&gt;Folder1\n\n    \n\nFile1\n\n File1   \n\nRoot-&gt;File1\n\n    \n\nSubfolder1\n\n Subfolder1   \n\nFolder1-&gt;Subfolder1\n\n    \n\nFile2\n\n File2   \n\nFolder1-&gt;File2\n\n    \n\nFile3\n\n File3   \n\nSubfolder1-&gt;File3\n\n    \n\nFile4\n\n File4   \n\nSubfolder1-&gt;File4\n\n    \n\nFile5\n\n File5   \n\nSubfolder1-&gt;File5\n\n   \n\n\nFigure 20.6: An example of a general tree representing a file system, where each node can have any number of child nodes.\n\n\n\n\nHowever, there are also more specialized types of trees, like Binary Trees, where each node can have at most two children, commonly referred to as left and right child. The binary tree can be visualized in the form of a family tree where each parent (node) can have at most two children (Figure 20.7).\n\n\n\n\n\n\n\n\nG\n\n  \n\nParent\n\n Parent   \n\nChild1\n\n Child1   \n\nParent-&gt;Child1\n\n    \n\nChild2\n\n Child2   \n\nParent-&gt;Child2\n\n   \n\n\nFigure 20.7: A binary tree representing a family tree, where each parent can have at most two children.\n\n\n\n\nA further specialization is the Binary Search Tree (BST), where the nodes are arranged in a manner such that for every node, nodes in the left subtree have values less than the node, and nodes in the right subtree have values greater than the node. This property makes BSTs useful for search operations, such as finding a book in a library system, where books are organized based on their identifying information (Figure 20.8).\n\n\n\n\n\n\n\n\nG\n\n  \n\n50\n\n 50   \n\n30\n\n 30   \n\n50-&gt;30\n\n    \n\n70\n\n 70   \n\n50-&gt;70\n\n    \n\n20\n\n 20   \n\n30-&gt;20\n\n    \n\n40\n\n 40   \n\n30-&gt;40\n\n    \n\n60\n\n 60   \n\n70-&gt;60\n\n    \n\n80\n\n 80   \n\n70-&gt;80\n\n   \n\n\nFigure 20.8: A binary search tree (BST) used in a library system for organizing books. The key property of BST is that nodes in the left subtree have values less than the parent node, and nodes in the right subtree have values greater.\n\n\n\n\nThere are also self-balancing trees like AVL Trees and Red-Black Trees that maintain their balance as new nodes are inserted or existing nodes are removed, which ensures that the tree remains efficient for operations like insertion, deletion, and search.\nAnother common type of tree is the B-tree, used in databases and filesystems. In a B-tree, each node can have more than two children, unlike in a binary tree. This structure allows for efficient access and modification of large blocks of data, which makes B-trees particularly suitable for use in disk-based storage systems, such as databases (Figure 20.9).\n\n\n\n\n\n\n\n\nG\n\n  \n\nNode1\n\n Node1   \n\nNode2\n\n Node2   \n\nNode1–Node2\n\n   \n\nNode3\n\n Node3   \n\nNode1–Node3\n\n   \n\nNode4\n\n Node4   \n\nNode1–Node4\n\n   \n\nLeaf1\n\n Leaf1   \n\nNode2–Leaf1\n\n   \n\nLeaf2\n\n Leaf2   \n\nNode2–Leaf2\n\n   \n\nLeaf3\n\n Leaf3   \n\nNode3–Leaf3\n\n   \n\nLeaf4\n\n Leaf4   \n\nNode3–Leaf4\n\n   \n\nLeaf5\n\n Leaf5   \n\nNode3–Leaf5\n\n   \n\nLeaf6\n\n Leaf6   \n\nNode4–Leaf6\n\n   \n\nLeaf7\n\n Leaf7   \n\nNode4–Leaf7\n\n  \n\n\nFigure 20.9: A representation of a B-tree used in a database. Each node can have more than two children, providing efficient access and modification of large data blocks.\n\n\n\n\nUnderstanding these types of trees and how they work is crucial to using them effectively. In the next sections, we will delve deeper into some of these tree types and explore their properties and uses."
  },
  {
    "objectID": "20_trees.html#binary-tree",
    "href": "20_trees.html#binary-tree",
    "title": "20  Tree Data Structure",
    "section": "20.3 Binary Tree",
    "text": "20.3 Binary Tree\nAfter understanding the basic concept of trees, let’s now focus on a special kind of tree, the Binary Tree. As we have mentioned earlier, in a binary tree, a node can have at most two children - commonly referred to as the left child and the right child. This property leads to some interesting and useful characteristics that we’ll explore in this section.\nThe structure of a binary tree is relatively straightforward. Each node in a binary tree contains some data, a reference to the left child node, and a reference to the right child node. If a node has no left or right child, the corresponding reference is set to null.\nIn a binary tree, each level has twice as many nodes as the previous level, creating a rapidly expanding structure. This property enables binary trees to store large amounts of data in a relatively small number of levels, which can lead to efficient search and insertion operations, given the tree is balanced.\nLet’s take a look at some different types of binary trees:\n\nFull Binary Tree: In this tree, every node has either 0 or 2 children. This type of tree is useful when you know that every internal node in your tree will have exactly two children. For example, in certain types of decision trees used in machine learning, each decision leads to two subsequent decisions, forming a full binary tree.\n\n\n\n\n\n\n\n\n\nG\n\n  \n\nA\n\n A   \n\nB\n\n B   \n\nA-&gt;B\n\n    \n\nC\n\n C   \n\nA-&gt;C\n\n    \n\nD\n\n D   \n\nB-&gt;D\n\n    \n\nE\n\n E   \n\nB-&gt;E\n\n   \n\n\nFigure 20.10: A Full Binary Tree. Every node has either 0 or 2 children.\n\n\n\n\n\nComplete Binary Tree: Every level, except possibly the last, is fully filled, and all nodes are as far left as possible. Heaps are an example of complete binary trees. In a heap, all levels are fully filled except for the last level, which is filled from left to right.\n\n\n\n\n\n\n\n\n\nG\n\n  \n\nA\n\n A   \n\nB\n\n B   \n\nA-&gt;B\n\n    \n\nC\n\n C   \n\nA-&gt;C\n\n    \n\nD\n\n D   \n\nB-&gt;D\n\n    \n\nE\n\n E   \n\nB-&gt;E\n\n    \n\nF\n\n F   \n\nC-&gt;F\n\n   \n\n\nFigure 20.11: A Complete Binary Tree. Every level is fully filled except for the last, which is filled from left to right.\n\n\n\n\n\nPerfect Binary Tree: A perfect binary tree is both full and complete. Every level is fully filled. This kind of tree appears in some specialized data structures or algorithms, but is not common in general use.\n\n\n\n\n\n\n\n\n\nG\n\n  \n\nA\n\n A   \n\nB\n\n B   \n\nA-&gt;B\n\n    \n\nC\n\n C   \n\nA-&gt;C\n\n    \n\nD\n\n D   \n\nB-&gt;D\n\n    \n\nE\n\n E   \n\nB-&gt;E\n\n    \n\nF\n\n F   \n\nC-&gt;F\n\n    \n\nG\n\n G   \n\nC-&gt;G\n\n   \n\n\nFigure 20.12: A Perfect Binary Tree. Every level is fully filled.\n\n\n\n\n\nBalanced Binary Tree: The difference in height of left and right subtrees for every node is not more than k (mostly 1). Most of the tree algorithms require the tree to be balanced to maintain their optimal time complexity.\n\n\n\n\n\n\n\n\n\nG\n\n  \n\nA\n\n A   \n\nB\n\n B   \n\nA-&gt;B\n\n    \n\nC\n\n C   \n\nA-&gt;C\n\n    \n\nD\n\n D   \n\nB-&gt;D\n\n    \n\nE\n\n E   \n\nB-&gt;E\n\n    \n\nF\n\n F   \n\nC-&gt;F\n\n   \n\n\nFigure 20.13: A Balanced Binary Tree. The difference in height of left and right subtrees for every node is not more than 1.\n\n\n\n\n\nDegenerate (or pathological) Tree: Each parent node has only one child. The tree behaves like a linked list, and we lose the advantages of binary trees.\n\n\n\n\n\n\n\n\n\nG\n\n  \n\nA\n\n A   \n\nB\n\n B   \n\nA-&gt;B\n\n    \n\nC\n\n C   \n\nB-&gt;C\n\n    \n\nD\n\n D   \n\nC-&gt;D\n\n    \n\nE\n\n E   \n\nD-&gt;E\n\n   \n\n\nFigure 20.14: A Degenerate (or pathological) Tree. Each parent node has only one child.\n\n\n\n\n\n20.3.1 Implementing a Binary Tree\nIn this section, we will be implementing a simple Binary Tree structure using Java. We’ll start with the definition of the Node class.\n/**\n * This class represents a node in the binary tree.\n * @param &lt;T&gt; This is the type parameter which represents the type of value the node will hold.\n */\npublic class Node&lt;T&gt; {\n    T value;\n    Node&lt;T&gt; left;\n    Node&lt;T&gt; right;\n\n    /**\n     * Node class constructor.\n     * @param value This is the value that the node will hold.\n     */\n    public Node(T value) {\n        this.value = value;\n        this.left = null;\n        this.right = null;\n    }\n}\nIn the code above, we defined a generic Node class with a type parameter T. The Node class has three fields: value of type T representing the data the node holds, and left and right of type Node&lt;T&gt; representing the left and right children of the node.\nNext, let’s define our BinaryTree class.\n/**\n * This class represents a binary tree.\n * @param &lt;T&gt; This is the type parameter which represents the type of value the nodes in the tree will hold.\n */\npublic class BinaryTree&lt;T&gt; {\n    Node&lt;T&gt; root;\n\n    /**\n     * BinaryTree class constructor.\n     */\n    public BinaryTree() {\n        this.root = null;\n    }\n\n    /**\n     * This method is used to add a value to the binary tree.\n     * @param value This is the value to be added.\n     */\n    public void add(T value) {\n        root = addRecursive(root, value);\n    }\n\n    /**\n     * This is a helper method for the add method. \n     * It is used to recursively find the place to add a new value.\n     * @param current This is the current node.\n     * @param value This is the value to be added.\n     * @return Node This returns the new node if current node is null, else it returns the current node.\n     */\n    private Node&lt;T&gt; addRecursive(Node&lt;T&gt; current, T value) {\n        if (current == null) {\n            return new Node&lt;&gt;(value);\n        }\n\n        // This compareTo method assumes the type T extends Comparable&lt;T&gt;. \n        // A more robust implementation may be required based on the actual type of T.\n        int cmp = ((Comparable&lt;T&gt;) value).compareTo(current.value);\n\n        if (cmp &lt; 0) {\n            current.left = addRecursive(current.left, value);\n        } else if (cmp &gt; 0) {\n            current.right = addRecursive(current.right, value);\n        }\n\n        return current;\n    }\n    // Additional methods for traversal or other operations can be added here.\n}\nIn the BinaryTree class, we defined a root of type Node&lt;T&gt; representing the root of the tree. The add method is used to add a new value to the tree. It uses the addRecursive helper method to find the correct place for the new value.\nNote that this is a basic implementation of a binary tree and only includes the ability to add elements. Practical applications of binary trees usually include additional operations like deleting a node, checking if a value exists in the tree, and various ways of traversing the tree (in-order, pre-order, post-order)."
  },
  {
    "objectID": "20_trees.html#common-operations-on-binary-trees",
    "href": "20_trees.html#common-operations-on-binary-trees",
    "title": "20  Tree Data Structure",
    "section": "20.4 Common Operations on Binary Trees",
    "text": "20.4 Common Operations on Binary Trees\n\n20.4.1 Traversals and Orderings\nTrees, being a nonlinear data structure, cannot be traversed in a single run like arrays, linked lists, or other linear data structures. Therefore, they require some specific methods to traverse their nodes, visit each node once, and perform some operations such as search, update, or accumulate.\nThree common types of depth-first traversal are in-order, pre-order, and post-order.\n\n20.4.1.1 In-Order Traversal\nIn in-order traversal, the process is as follows: 1. Traverse the left subtree 2. Visit the root node 3. Traverse the right subtree\nThis traversal technique is widely used, and in binary search trees, it retrieves data in ascending order.\n\n\n\n\n\n\n\n\nG\n\n  \n\nA\n\n 2 A   \n\nB\n\n 1 B   \n\nA-&gt;B\n\n    \n\nC\n\n 3 C   \n\nA-&gt;C\n\n   \n\n\nFigure 20.15: In-Order Traversal: Traverse left subtree, Visit root, Traverse right subtree. The numbers indicate the order of traversal.\n\n\n\n\nPseudocode for in-order traversal can look like this:\nfunction inOrderTraversal(node) {\n  if (node != null) {\n    inOrderTraversal(node.left)\n    visit(node)\n    inOrderTraversal(node.right)\n  }\n}\n\n\n20.4.1.2 Pre-Order Traversal\nIn pre-order traversal, the process is as follows: 1. Visit the root node 2. Traverse the left subtree 3. Traverse the right subtree\nThis method can be used to create a copy of the tree, or to get a prefix expression of an expression tree.\n\n\n\n\n\n\n\n\nG\n\n  \n\nA\n\n 1 A   \n\nB\n\n 2 B   \n\nA-&gt;B\n\n    \n\nC\n\n 3 C   \n\nA-&gt;C\n\n   \n\n\nFigure 20.16: Pre-Order Traversal: Visit root, Traverse left subtree, Traverse right subtree. The numbers indicate the order of traversal.\n\n\n\n\nPseudocode for pre-order traversal can look like this:\nfunction preOrderTraversal(node) {\n  if (node != null) {\n    visit(node)\n    preOrderTraversal(node.left)\n    preOrderTraversal(node.right)\n  }\n}\n\n\n20.4.1.3 Post-Order Traversal\nIn post-order traversal, the process is as follows: 1. Traverse the left subtree 2. Traverse the right subtree 3. Visit the root node\nThis method is used to delete or deallocate nodes of a tree, or to get a postfix expression of an expression tree.\n\n\n\n\n\n\n\n\nG\n\n  \n\nA\n\n 3 A   \n\nB\n\n 1 B   \n\nA-&gt;B\n\n    \n\nC\n\n 2 C   \n\nA-&gt;C\n\n   \n\n\nFigure 20.17: Post-Order Traversal: Traverse left subtree, Traverse right subtree, Visit root. The numbers indicate the order of traversal.\n\n\n\n\nPseudocode for post-order traversal can look like this:\nfunction postOrderTraversal(node) {\n  if (node != null) {\n    postOrderTraversal(node.left)\n    postOrderTraversal(node.right)\n    visit(node)\n  }\n}\nIn each of the traversal methods above, visit(node) is an operation that performs some computation on node, such as printing its value.\nIt’s important to note that traversal operations have a time complexity of O(n), where n is the number of nodes in the tree. This is because every node must be visited once and only once during the traversal.\nIn addition to traversal methods, other common operations on binary trees include insertion, deletion, and searching. These are vital operations for maintaining and interacting with the binary tree structure.\n\n\n\n20.4.2 Removing Nodes from a Binary Tree\nDeleting or removing a node from a binary tree is a slightly complex operation compared to insertion. This is because when we remove a node, we need to ensure that the remaining nodes still form a binary tree. The process differs depending on the number of children the node has:\n\nNo child: If the node is a leaf node (i.e., it does not have any children), we can directly remove the node.\n\n\n\n\n\n\n\n\n\nG\n\n  \n\nA\n\n A   \n\nB\n\n B   \n\nB-&gt;A\n\n  remove   \n\nC\n\n C   \n\nB-&gt;C\n\n   \n\n\nFigure 20.18: Removing a node with no children. The node ‘C’ is simply removed from the tree.\n\n\n\n\n\nOne child: If the node has a single child, we can replace the node with its subtree.\n\n\n\n\n\n\n\n\n\nG\n\n  \n\nA\n\n A   \n\nB\n\n B   \n\nB-&gt;A\n\n  remove   \n\nC\n\n C   \n\nB-&gt;C\n\n    \n\nD\n\n D   \n\nC-&gt;D\n\n   \n\n\nFigure 20.19: Removing a node with one child. The node ‘B’ is replaced by its subtree rooted at ‘C’.\n\n\n\n\n\nTwo children: This is the most complex case. If the node has two children, we generally seek a node from the tree to replace the node to be deleted. The replacement node is typically the in-order predecessor or the in-order successor of the node. These are the node’s immediate previous and next nodes in in-order traversal (see Figure 20.15).\n\nIn-order predecessor: This is the node with the highest value that is smaller than the value of the node to be removed. It can be found by moving one step to the left (to the left child), and then as far right as possible.\nIn-order successor: This is the node with the smallest value that is larger than the value of the node to be removed. It can be found by moving one step to the right (to the right child), and then as far left as possible.\n\n\n\n\n\n\n\n\n\n\nG\n\n  \n\nA\n\n A   \n\nB\n\n B   \n\nB-&gt;A\n\n    \n\nC\n\n C   \n\nB-&gt;C\n\n   \n\n\nFigure 20.20: Removing a node with two children. The node ‘B’ is replaced by its in-order predecessor ‘A’ or in-order successor ‘C’. The replacement node is then recursively removed from its original position.\n\n\n\n\nOnce we find the in-order predecessor (or successor), we replace the node to be deleted with the predecessor (or successor) and then recursively delete the predecessor (or successor) from its original position.\nThe reason we choose the in-order predecessor or successor is to maintain the binary search tree property, i.e., for every node, nodes in the left subtree have values less than the node, and nodes in the right subtree have values greater than the node.\nHere is a basic outline of the removal process in pseudocode:\nfunction remove(node, key) {\n  if (node is null) {\n    return node\n  }\n  if (key &lt; node.key) {\n    node.left = remove(node.left, key)\n  } else if (key &gt; node.key) {\n    node.right = remove(node.right, key)\n  } else {\n    if (node.left is null) {\n      return node.right\n    } else if (node.right is null) {\n      return node.left\n    }\n    node.key = minValue(node.right)\n    node.right = remove(node.right, node.key)\n  }\n  return node\n}\n\nfunction minValue(node) {\n  current = node\n  while (current.left is not null) {\n    current = current.left\n  }\n  return current.key\n}\nIn this pseudocode, remove() is a recursive function that deletes the node with the specified key from the tree and returns the new root of the subtree, and minValue() is a helper function that returns the minimum value in a non-empty binary search tree.\nThe time complexity for deletion in a binary tree can range from O(log n) to O(n), where n is the number of nodes. In a balanced tree, the time complexity is O(log n) because we would be traversing the height of the tree, which is logarithmic in a balanced tree. However, in the worst-case scenario, such as when the tree is a degenerate or skewed tree, the time complexity would be O(n) because each removal could potentially involve traversing all the nodes of the tree."
  },
  {
    "objectID": "20_trees.html#binary-search-trees-bst",
    "href": "20_trees.html#binary-search-trees-bst",
    "title": "20  Tree Data Structure",
    "section": "20.5 Binary Search Trees (BST)",
    "text": "20.5 Binary Search Trees (BST)\nBefore delving into Binary Search Trees (BSTs), let’s take a step back and contemplate the significance of search operations in computer science. A search operation is fundamental to many applications, from looking up a contact in your smartphone to searching for a specific book in a library database. Therefore, making search operations efficient has always been a central challenge in computer science.\nTraditional search approaches like linear search, which checks each item one by one, can be time-consuming especially when dealing with large datasets, as it has a time complexity of O(n). A considerable improvement is the binary search algorithm, which works by repeatedly dividing the sorted list of elements in half until the target element is found, giving it a time complexity of O(log n). However, binary search requires the data to be sorted, and maintaining a sorted list of elements can be expensive for insert and delete operations.\nThis is where Binary Search Trees come in. A Binary Search Tree is a special type of binary tree that maintains a specific ordering property — for each node, all elements in the left subtree are less than the node, and all elements in the right subtree are greater than the node (see Figure 20.21). This property of BSTs enables us to perform search, insert, and delete operations efficiently, maintaining a time complexity of O(log n) in an ideal situation where the tree is balanced. Let’s explore these concepts in more detail.\n\n20.5.1 Definition, Properties, and Structure of BSTs\nA Binary Search Tree (BST) is a binary tree where for every node:\n\nThe values in its left subtree are less than the node’s value.\nThe values in its right subtree are greater than the node’s value.\n\n\n\n\n\n\n\n\n\nG\n\n  \n\n5\n\n 5   \n\n3\n\n 3   \n\n5-&gt;3\n\n    \n\n7\n\n 7   \n\n5-&gt;7\n\n    \n\n2\n\n 2   \n\n3-&gt;2\n\n    \n\n4\n\n 4   \n\n3-&gt;4\n\n    \n\n6\n\n 6   \n\n7-&gt;6\n\n    \n\n8\n\n 8   \n\n7-&gt;8\n\n   \n\n\nFigure 20.21: The Binary Search Tree property: for every node, all elements in the left subtree are less than the node, and all elements in the right subtree are greater than the node.\n\n\n\n\nThis property ensures that the “in-order” traversal of a BST results in a sorted sequence of values, which is the key to efficient search, insertion, and deletion operations.\n\n\n20.5.2 Advantages of BSTs over other tree structures\nThe BST property provides some advantages over other tree structures:\n\nEfficient search: If the tree is balanced, we can find, insert, or delete entries in O(log n) time where n is the total number of nodes. This is significantly faster than linear search, and it doesn’t require the maintenance of a sorted list like binary search.\nSorted traversal: In-order traversal of a BST yields the nodes in sorted order, which can be useful in various applications.\nFlexibility: Unlike an array, BSTs do not have a fixed size. They can grow and shrink during the execution of the program, allowing efficient use of memory.\n\n\n\n20.5.3 Detailed description of BST operations: insertion, deletion, searching\nBSTs support three fundamental operations: search, insertion, and deletion, all of which leverage the BST property to operate efficiently.\nSearch: Starting from the root, if the target value is less than the current node, we move to the left child; if it’s greater, we move to the right child. We repeat this process until we either find the target value or reach a null where the target value should be if it were in the tree (see Figure 20.22).\n\n\n\n\n\n\n\n\nG\n\n  \n\n5\n\n 5   \n\n3\n\n 3   \n\n5-&gt;3\n\n    \n\n7\n\n 7   \n\n5-&gt;7\n\n    \n\n2\n\n 2   \n\n3-&gt;2\n\n    \n\n4\n\n 4   \n\n3-&gt;4\n\n    \n\n6\n\n 6   \n\n7-&gt;6\n\n    \n\n8\n\n 8   \n\n7-&gt;8\n\n   \n\n\nFigure 20.22: BST search operation: Starting from the root, the algorithm compares the target value with the current node and moves left or right based on the comparison. The search ends when the target is found or when a null is encountered.\n\n\n\n\nInsertion: Similar to search, but when we reach a null location, we create a new node with the target value at that spot (see Figure 20.23).\n\n\n\n\n\n\n\n\nG\n\n  \n\n5\n\n 5   \n\n3\n\n 3   \n\n5-&gt;3\n\n    \n\n7\n\n 7   \n\n5-&gt;7\n\n    \n\n2\n\n 2   \n\n3-&gt;2\n\n    \n\n4\n\n 4   \n\n3-&gt;4\n\n    \n\n6\n\n 6   \n\n7-&gt;6\n\n    \n\n8\n\n 8   \n\n7-&gt;8\n\n    \n\n1\n\n 1   \n\n2-&gt;1\n\n   \n\n\nFigure 20.23: BST insertion operation: Similar to the search operation, the algorithm moves down the tree starting from the root. When a null location is encountered, a new node is created at that spot.\n\n\n\n\nDeletion: A bit more complicated as we need to maintain the BST property after removing a node. The process varies based on the number of children the node to be deleted has\n, similar to deletion in a binary tree (see Figure 20.24).\n\n\n\n\n\n\n\n\nG\n\n  \n\n5\n\n 5   \n\n3\n\n 3   \n\n5-&gt;3\n\n    \n\n7\n\n 7   \n\n5-&gt;7\n\n    \n\n2\n\n 2   \n\n3-&gt;2\n\n    \n\n4\n\n 4   \n\n3-&gt;4\n\n    \n\n6\n\n 6   \n\n7-&gt;6\n\n    \n\n8\n\n 8   \n\n7-&gt;8\n\n    \n\n1\n\n 1   \n\n2-&gt;1\n\n   \n\n\nFigure 20.24: BST deletion operation: Deletion in a BST can be complex as it must maintain the BST property after removing a node. The process varies depending on whether the node to be deleted has no children, one child, or two children.\n\n\n\n\nAbsolutely. Let’s break down the implementation of BST operations into both recursive and iterative approaches using Java.\n\n\n20.5.4 Recursive and Iterative Implementations in Java\nWhile recursion offers a straightforward and elegant approach to implementing BST operations, the iterative method can often provide better performance in terms of space complexity. Let’s look at both methods for each of the main BST operations: search, insertion, and deletion.\n\n\n20.5.5 Search Operation\nRecursive Approach\npublic TreeNode search(TreeNode node, int value) {\n    if (node == null || node.val == value)\n        return node;\n\n    if (node.val &gt; value)\n        return search(node.left, value);\n    \n    return search(node.right, value);\n}\nIterative Approach\npublic TreeNode search(TreeNode root, int value) {\n    while (root != null) {\n        if (root.val &gt; value)\n            root = root.left;\n        else if (root.val &lt; value)\n            root = root.right;\n        else\n            return root;\n    }\n    return null;\n}\n\n\n20.5.6 Insertion Operation\nRecursive Approach\npublic TreeNode insert(TreeNode node, int value) {\n    if (node == null) {\n        return new TreeNode(value);\n    }\n\n    if (value &lt; node.val) {\n        node.left = insert(node.left, value);\n    } else if (value &gt; node.val) {\n        node.right = insert(node.right, value);\n    }\n\n    return node;\n}\nIterative Approach\npublic TreeNode insert(TreeNode root, int value) {\n    TreeNode node = new TreeNode(value);\n    if (root == null) {\n        return node;\n    }\n\n    TreeNode parent = null, current = root;\n    while (current != null) {\n        parent = current;\n        if (current.val &gt; value) {\n            current = current.left;\n        } else {\n            current = current.right;\n        }\n    }\n\n    if (parent.val &gt; value) {\n        parent.left = node;\n    } else {\n        parent.right = node;\n    }\n\n    return root;\n}\n\n\n20.5.7 Deletion Operation\nRecursive Approach\npublic TreeNode delete(TreeNode root, int value) {\n    if (root == null) {\n        return root;\n    }\n\n    if (value &lt; root.val) {\n        root.left = delete(root.left, value);\n    } else if (value &gt; root.val) {\n        root.right = delete(root.right, value);\n    } else {\n        if (root.left == null)\n            return root.right;\n        else if (root.right == null)\n            return root.left;\n\n        root.val = findMinValue(root.right);\n        root.right = delete(root.right, root.val);\n    }\n\n    return root;\n}\n\nprivate int findMinValue(TreeNode root) {\n    int min = root.val;\n    while (root.left != null) {\n        min = root.left.val;\n        root = root.left;\n    }\n    return min;\n}\nPlease note that the iterative implementation of delete operation is relatively complex and can detract from the understanding of how the delete operation fundamentally works. Therefore, we generally prefer the recursive approach for teaching purposes. However, once you are comfortable with the recursive implementation, it’s worthwhile to try to implement the iterative version on your own for practice.\nThe presented examples illustrate how different BST operations can be performed in both recursive and iterative manner. Each has its own pros and cons - recursive methods are often easier to comprehend and write, whereas iterative methods might provide better performance.\n\n\n20.5.8 Performance and Time Complexity\nThe time complexity of binary search tree operations such as search, insert, and delete depends on the height of the binary search tree. In the best-case scenario, the tree is perfectly balanced, and its height is log(n), where n is the number of nodes. In this case, search, insert, and delete operations can be performed in O(log n) time. However, in the worst-case scenario, the tree can become skewed, which means it resembles a linked list more than a tree. In this case, the height of the tree is n, and operations can take up to O(n) time.\nLet’s see how this plays out for each operation:\nSearch Operation\n\nBest-case performance: O(log n) – This is when the tree is balanced, and we can eliminate half of the nodes from our search at each step.\nWorst-case performance: O(n) – This happens when the tree is skewed, and our search path includes most or all nodes in the tree.\n\nInsert Operation\n\nBest-case performance: O(log n) – When the tree is balanced, the location for a new node is found by traversing from the root to the appropriate leaf node.\nWorst-case performance: O(n) – In a skewed tree, the new node could end up being a child of the deepest leaf node.\n\nDelete Operation\n\nBest-case performance: O(log n) – In a balanced tree, we find the node to delete quickly. If the node has two children, we also need time to find the in-order predecessor or successor.\nWorst-case performance: O(n) – In a skewed tree, deletion can involve traversing most of the tree.\n\nOne thing to note is that the best-case scenario, a balanced tree, is not the average case. Unless measures are taken to balance the tree, binary search trees can become skewed from sequences of insertions and deletions.\nThe next topic that we’ll discuss, self-balancing binary search trees, will address this limitation of the basic binary search tree by ensuring that the tree remains approximately balanced at all times. As a result, self-balancing binary search trees can guarantee that the time complexity of major operations is always O(log n), which is a significant improvement in the worst-case scenario."
  },
  {
    "objectID": "20_trees.html#balanced-binary-search-trees",
    "href": "20_trees.html#balanced-binary-search-trees",
    "title": "20  Tree Data Structure",
    "section": "20.6 Balanced Binary Search Trees",
    "text": "20.6 Balanced Binary Search Trees\nBinary search trees (BSTs) are powerful data structures that support efficient search, insertion, and deletion operations. However, if the tree becomes unbalanced, these operations could degrade to linear time complexity. One effective way to mitigate this issue is by employing balanced binary search trees, such as AVL Trees and Red-Black Trees. These trees aim to maintain balance, ensuring efficient performance regardless of the input sequence.\nThe concept of a “balanced” tree might sound abstract, so let’s make it tangible with an example (Figure 20.25). A balanced binary tree is one where the difference between the heights of the left and right subtrees of every node is either -1, 0, or 1. This balance ensures that the tree doesn’t lean too heavily on one side, optimizing the path to every node and promoting efficiency.\n\n\n\n\n\n\n\n\nG\n\n  \n\n6\n\n 6   \n\n4\n\n 4   \n\n6-&gt;4\n\n    \n\n8\n\n 8   \n\n6-&gt;8\n\n    \n\n2\n\n 2   \n\n4-&gt;2\n\n    \n\n5\n\n 5   \n\n4-&gt;5\n\n    \n\n7\n\n 7   \n\n8-&gt;7\n\n    \n\n9\n\n 9   \n\n8-&gt;9\n\n    \n\n1\n\n 1   \n\n2-&gt;1\n\n    \n\n3\n\n 3   \n\n2-&gt;3\n\n   \n\n\nFigure 20.25: A balanced binary search tree. The numbers show the height of each node.\n\n\n\n\nConsider a balance scale, with nodes as the weights. When equally balanced, the scale maintains equilibrium. However, adding or subtracting weights (or nodes) disturbs this balance, causing the scale to lean towards the heavier side. AVL Trees and Red-Black Trees work similarly - they maintain equilibrium by redistributing the weights, which we call “rotations” in the context of trees.\nAVL Trees, named after their inventors Adelson-Velsky and Landis, adjust their balance through a process called rotation. This operation preserves the in-order property of the tree. If the balance factor of a node in an AVL tree becomes 2 or -2, a rotation is performed to regain balance. Let’s illustrate this with a simple example (Figure 20.29).\nConsider inserting 1, 2, 3 into an initially empty AVL tree.\n\nInserting 1 gives us:\n\n\n\n\n\n\n\n\n\nG\n\n  \n\n1\n\n 1  \n\n\nFigure 20.26: Inserting 1 into an empty AVL tree.\n\n\n\n\n\nInserting 2 gives us:\n\n\n\n\n\n\n\n\n\nG\n\n  \n\n1\n\n 1   \n\n2\n\n 2   \n\n1-&gt;2\n\n   \n\n\nFigure 20.27: Inserting 2 into the AVL tree.\n\n\n\n\n\nInserting 3 unbalances the tree:\n\n\n\n\n\n\n\n\n\nG\n\n  \n\n1\n\n 1   \n\n2\n\n 2   \n\n1-&gt;2\n\n    \n\n3\n\n 3   \n\n2-&gt;3\n\n   \n\n\nFigure 20.28: Inserting 3 into the AVL tree results in an unbalanced tree.\n\n\n\n\nThis structure is unbalanced and equivalent to a linked list. The balance factor for node 1 is -2, indicating a required rotation.\n\nWe perform a left rotation around the root (node 1), resulting in a balanced tree:\n\n\n\n\n\n\n\n\n\nG\n\n  \n\n2\n\n 2   \n\n1\n\n 1   \n\n2-&gt;1\n\n    \n\n3\n\n 3   \n\n2-&gt;3\n\n   \n\n\nFigure 20.29: A left rotation around the root balances the AVL tree.\n\n\n\n\nThe AVL Tree is now balanced, and all operations are guaranteed logarithmic time complexity.\nRed-Black Trees offer another solution, painting each node one of two colors – red or black – and maintaining balance by adhering to red-black properties. Although the rules and operations are more complex, they also ensure the tree remains approximately balanced during additions and deletions. A Red-Black Tree would be great to visualize, but given its complexity, it’s better to explore it interactively or in more advanced courses.\nThese tree structures may seem complicated, but they highlight how well-understood tools like a binary tree can be further optimized for efficiency. While we’ve only scratched the surface here, you’ll delve deeper into these and other types of self-balancing trees in advanced data structures courses. The goal is not to memorize every detail but to appreciate the breadth of tools available for different use cases.\nIn your journey as a computer scientist, you’ll encounter various real-world scenarios where maintaining efficiency is vital. From databases to file systems, different applications require different tools. Understanding the principles behind these tools, such as the importance of balance in BSTs, will empower you to make informed decisions in your work.\nWith this, we conclude our journey into the world of binary trees and binary search trees. We hope that the concepts, examples, and code shared in this chapter help illuminate these fundamental data structures. Remember that learning is a process - with every step, you’re building a stronger foundation in computer science. Keep practicing, keep questioning, and keep exploring."
  }
]